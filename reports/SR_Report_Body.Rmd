

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
require("knitr")
opts_knit$set(root.dir = "..") #  I put this in to raise up the working directory from the reports folder (where the rmd lives) to one level above
```





# Abstract



# Introduction


Cognitive screening tools are measures designed to detect cognitive impairment through brief means. These either target one highly predictive ability or are addressed at a set of core domains (language, memory, orientation) using a minimal set of items for each. Measures considered cognitive screens are typically those that can be completed within 20 minutes [@Cullen2007] and are not an alternative to fuller neuropsychological test batteries, which are more comprehensive and sensitive. Cognitive screening occurs in a wide variety of contexts such as patients with brain tumours, psychiatric disorders, or traumatic brain injuries [@RoebuckSpencer2017]; however screening for dementia is a rationale behind the construction of many . 

Cognitive screens are not intended to be diagnostic, although low scores that corroborate clear deficits found in a clinical examination and interview may be considered sufficient without further cognitive investigation. Outside of this context, cognitive screen performance contributes to the decision whether more investigation is required. Key here is that cognitive screens are sufficiently sensitive - correctly identifying when followup is warranted, to maximise early diagnosis - and specific - avoiding putting people on an investigative pathway when this is not necessary [@Cullen2007].


These concerns are relevant when a population lives with a cognition-affecting condition that is not the disease being screened for, such as experiencing chronic pain. Pain is known to affect performance on focused neuropsychologicalcognitive tests and batteries  (see xx for a review). This is likely to reflect a combination of depletion of resources, distracting effects of pain symptoms disrupting attention, and in the case of chronic pain possible longer-term changes to the nervous system either due to sustained pain or the condition that produces it. As chronic pain is more prevalent with aging, it is important to understand whether the experience impacts cognition sufficiently to result in alterations of cognitive screen responding.




<!-- ============================  -->

# Method

The study followed the PRISMA guidelines for reporting SRs and MAs [@Moher2009].

 The protocol of the study was registered with the International Prospective Register of Systematic Reviews (PROSPERO) [registration number: CRD 42021272835] and published elsewhere (EG ZZZZ Martín-Gómez et al.,
2020).

## Search strategy

Searches were conducted through the bibliographic databases Embase (1947-present), Medline (1946-present), and PsychInfo, as a mapping of articles identified in preliminary searches showed saturation by the use of these databases. OpenGrey (System for Information on Grey Literature in Europe) was additionally searched ??? Currently down.


The search was performed using the PICO model. It used medical headings and keywords associated with pain and cognitive screening instruments.Searches were initially piloted in PsychInfo before adaptation for use in the other databases. The search strategy for each database can be found in Appendix XXXX. PROSPERO and Epistimonikos were searched for similar ongoing or recently completed SRs.



## Eligibility criteria

The review focused on primary research that involved a participant group experiencing chronic pain and a control group without that experience. 
Studies had to include participants completion of a cognitive screen. Definitions of cognitive screen are varied and the subject of a number of previous systematic reviews [eg @Ashford2008, @Cullen2007], and the decision was made to utilise a practitioner definition provided in @AlzheimersSociety2013 which reports nine screens agreed by UK clinicians to be the focus of common clinical practice. Studies using different editions and language variants of these screens were also eligible. 

Study design was not strictly defined, and could include cross-sectional designs as well as experimental designs including those introducing treatment such as medication, as long as cognitive screening information was available for both groups, and reporting was not clearly confounded by the impact of the treatment. This was rarely the case as screen information tended to be collected at baseline for these studies. 

## Study selection
After acquiring search results and removal of duplicates, two initial co-review stages were taken by reviewers 1 (AF) and 2 (JM): firstly to calibrate the eligibility checklist on 10 results and agree refinements, and then to independently screen 120 titles and abstracts against inclusion criteria, and then discuss discrepancies in judgment until reaching consensus on all cases, consulting with a third author where necessary.

Following this step the full texts of retained studies were reviewed starting with an eligibility calibration on 2 papers, followed by independent screening of 20 further full texts by the same two reviewers, addressing discrepancies in a similar manner. Reviewer 1 then completed the full text review on all remaining results. Authors were contacted when full articles are unavailable (n=1).

## Data extraction

Relevant data included type of pain condition, participant details,  measures of pain and mood and scores on the cognitive screening test, as well as whether the test was key or incidental to the study (e.g. a baseline measure).

Data was extracted by reviewer 1, with reviewer 2 performing a check to ensure accurate extraction on 5 consecutive papers, which was achieved after xxx.

Where data was presented in the form of median and inter-quartile range, this was converted into estimated mean and standard deviation using the estmeansd r package using the Box–Cox method described in @McGrath2020.

## Risk of bias 
 <!-- this is not found in every one  -->

## Assessment of publication bias ??
<!-- this is not found in every one  -->

Maybe only for those for which screening was key to the study

## Data analysis

## Quality of evidence / Quality assessment tool

Study quality was assessed using the JBI Critical Appraisal Checklist for Analytical Cross Sectional Studies (REF). This scale rates studies on eight criteria such as inclusion criteria, description of study, outcome measurement and strategies to deal with confounding factors. The checklist includes items that required some translation to relevance for this review: for instance, measurement of exposure (treatment) did not have a bearing on quality of the cognitive screening data, but lack of clarity regarding the order of treatment and screening did. Supplementary guidance was constructed as can be seen in the appendix.

<!-- ============================  -->

# Results

 <!-- ================== https://ardata-fr.github.io/officeverse/officedown-for-word.html#insert-sections==========  -->
<!---BLOCK_LANDSCAPE_START--->

``` {r, echo = F}
library("flextable")
library("ftExtra")
library("dplyr")
library("officer")

dat2 <- tibble::tribble(
                ~biblio, ~Order, ~study.id, ~extraction.date,    ~reviewer.stage,                                                                                                                                                                      ~author,                                                                                                             ~title,   ~country,
          "AlMalki2020",     9L,  "ALM009",           44624L, "full-text-review",                                                                                 "Al-Malki,Daifallah;Kotb,Mamdouh Ali;Kamal,Ahmed M.;Abd El Fatah, Aliaa S.;Ahmed,Yassmin M.", "Cognitive performance in patients with chronic tension-type headache and its relation to neuroendocrine hormones",   "Egypt?",
          "Cardoso2021",    16L,  "APA016",           44624L,       "pre-search",                   "Apagueno,Brandon;Hoyos,Lorraine;Cardoso,Josue;Lysne,Paige;Riley,Joseph L.;Fillingim,Roger B.;Porges,Eric;Woods,Adam J.;Cohen,Ronald;Cruz-Almeida,Yenisel",                                                       "Pain and the Montreal Cognitive Assessment (MoCA) in Aging",      "USA",
  "BarceloMartinez2018",    26L,  "BAR026",           44624L, "full-text-review", "Barceló-Martinez,Ernesto;Gelves-Ospina,Melissa;Lechuga,Edgar Navarro;Allegri,Ricardo F.;Orozco-Acosta,Erick;Benítez-Agudelo,Juan C.;León-Jacobus,Alexandra;Román,Néstor F.",                 "Serum cortisol levels and neuropsychological impairments in patients diagnosed with fibromyalgia", "Colombia"
  )

dat3 <- dat2 %>%
  mutate(biblio_comp = paste0("@",biblio))


#dat3 <- dat2 %>%
#  select(author, study.id, biblio_comp)





test <- dat3 %>%
  flextable() %>%
  colformat_md() %>%
  autofit()

test 

```

<!---BLOCK_LANDSCAPE_STOP--->


Include in table: 

Study (first named author)
Pain condition
pain reporting
Age c
Age t
n
% gender? across both?
Cognition:
key
SMD 
reported sig?
cut-off employed?
mood diff that was not controlled for in some way (Yes/No/Unknown)
medication diff

## Study selection

## Study characteristics
<!-- this is not found in every one  -->

## Participants 
<!-- this is not found in every one  -->


## Type of screen
<!-- this is not found in every one  -->

## Risk of bias of the included studies

## Impact of chronic pain upon cognitive screen performance

## Publication bias

## Subgroup analysis, meta-regression and stratified meta-analysis

## Confounds



## Quality of evidence


<!-- ============================  -->

# Discussion
<!-- some do not break down this way -->

## Summary of findings

## Comparison with previous research

## Meaning and implications

## Strengths and limitations

## Future research

 



## Patient data




# Results



